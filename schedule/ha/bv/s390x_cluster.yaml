---
name: s390x_cluster.yaml
description: >
  S390x cluster Test. Schedule for the zalpha cluster.

  Currently, SLES+HA tests on s390x are run using the svirt backend (zKVM),
  where the  openqa workers control via virsh commands, SSH and VNC, a KVM guest
  on an s390x LPAR host; since networking is provided by the LPAR itself, there
  is no current way to deploy a Support Server in this scenario, as such,
  network services are provided outside of the openqa infrastructure.

  Some settings are required in the job group or test suite for this schedule to
  work.

  The other settings required in the job group are.

  CLUSTER_NAME must be defined for all jobs as a string. HA_CLUSTER_INIT must be
  defined to yes in the job that initializes the cluster
  HA_CLUSTER_JOIN must be defined for the rest of the jobs, and it must contain the
  hostname of the job where HA_CLUSTER_INIT is defined to yes
  HOSTNAME must be defined to different hostnames for each node.
  All jobs with the exception of the parent job must include a PARALLEL_WITH setting
  referencing the parent job.
  HA_UNICAST must be set to 1 because we can not configure multicast corosync on
  s390x. ISCSI_LUN_INDEX must be set to an available LUN Id starting point,  HA
  tests will take 5 consecutive LUNs; 1 for SBD, 2 for cluster_md and 2 for
  drbd_passive. Be very careful with that settings because you may erase LUNs
  used by other tests. More information here,
  https://gitlab.suse.de/hsehic/qa-css-docs/-/blob/master/ha/openqa.md#information-specific-to-s390x-tests
  ISCSI_SERVER must be set to the iscsi server ip address. And of course,
  YAML_SCHEDULE must point to this file.

  Below are the optional settings.

  HA_CLUSTER_DRBD can be defined for enabling DRBD test. HA_REMOVE_NODE can be
  defined for testing a node removal. USE_SYSRQ_FENCING can be defined for
  fencing through sysrq instead of 'crm node fence' command.
vars:
  BOOT_HDD_IMAGE: '1'
  DESKTOP: 'textmode'
  HA_CLUSTER: '1'
  HA_UNICAST: '1'
  HDDMODEL: 'scsi-hd'
  HDD_SCC_REGISTERED: '1'
  QEMU_DISABLE_SNAPSHOTS: '1'
  TIMEOUT_SCALE: '2'
  USE_LVMLOCKD: '1'
schedule:
  - '{{barrier_setup}}'
  - installation/bootloader_zkvm
  - boot/boot_to_desktop
  - ha/wait_barriers
  - console/system_prepare
  - console/consoletest_setup
  - console/check_os_release
  - console/hostname
  - ha/ha_sle15_workarounds
  - ha/firewall_disable
  - ha/iscsi_client
  - ha/setup_hosts_and_luns
  - ha/watchdog
  - '{{cluster_setup}}'
  - ha/check_hawk
  - ha/dlm
  - ha/clvmd_lvmlockd
  - ha/cluster_md
  - ha/vg
  - ha/filesystem
  - '{{drbd}}'
  - ha/fencing
  - '{{boot_to_desktop_node01}}'
  - ha/check_after_reboot
  - '{{remove_node}}'
  - ha/check_logs
conditional_schedule:
  barrier_setup:
    HA_CLUSTER_INIT:
      yes:
        - ha/barrier_init
  cluster_setup:
    HA_CLUSTER_INIT:
      yes:
        - ha/ha_cluster_init
      no:
        - ha/ha_cluster_join
  drbd:
    HA_CLUSTER_DRBD:
      1:
        - ha/drbd_passive
        - ha/filesystem
  boot_to_desktop_node01:
    HA_CLUSTER_INIT:
      yes:
        - boot/boot_to_desktop
  remove_node:
    HA_REMOVE_NODE:
      1:
        - ha/remove_node
